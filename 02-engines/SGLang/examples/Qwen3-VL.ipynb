{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993dcf59-dd85-4a31-a8cc-02c5d4be5dfe",
   "metadata": {},
   "source": [
    "# Deploy a model on SageMaker Endpoint with SGLang container using AWS Python API (boto3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd8345-fc96-4a77-9e70-58d6a5d11809",
   "metadata": {},
   "source": [
    "In this notebook we will deploy `Qwen/Qwen3-VL-30B-A3B-Thinking` model on Amazon SageMaker AI Endpoint using SGLang container.\n",
    "\n",
    "\n",
    "***We assume that you already have SGLang container built and pushed to the ECR registry in your account.***\n",
    "\n",
    "***If you need instructions how to do this please refer to the `README.md` in the parent directory***\n",
    "\n",
    "\n",
    "## Qwen3-VL-30B-A3B-Instruct\n",
    "- **Parameters**: 31B (Mixture of Experts)\n",
    "- **Instance Type**: ml.g6.12xlarge\n",
    "- **GPUs**: 4 NVIDIA L40S Tensor Core GPUs with 192 GB of total GPU memory (48 GB of memory per GPU)\n",
    "- **Highlights**: High accuracy for complex visual reasoning. Medical imaging, scientific research, advanced OCR.\n",
    "\n",
    "## Model Capabilities \n",
    "- Advanced spatial perception (2D/3D reasoning)\n",
    "- Multi-language OCR (32 languages)\n",
    "- Visual agent functionality\n",
    "- Video understanding with timestamps\n",
    "- Visual coding generation\n",
    "- Context Length: 256K tokens (expandable to 1M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01a4b2-b0d3-420c-8335-4efd984bb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker==2.245.0 --upgrade --quiet --no-warn-conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183bf15-3f3f-4d70-91da-fe269ff421b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")  # client to intreract with SageMaker\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")  # client to intreract with SageMaker Endpoints\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "print(f\"boto3 version: {boto3.__version__}\")\n",
    "print(f\"sagemaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdb7fb-319f-4db9-92ea-0c7a94212365",
   "metadata": {},
   "source": [
    "## Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b45a5-0c97-470e-84e2-5bb1d01f089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image = f\"{account_id}.dkr.ecr.us-east-1.amazonaws.com/sglang:v0.5.4\"\n",
    "\n",
    "instance = {\"type\": \"ml.g6e.12xlarge\", \"num_gpu\": 4}\n",
    "\n",
    "model_id = \"Qwen/Qwen3-VL-30B-A3B-Thinking\"\n",
    "model_name = sagemaker.utils.name_from_base(\"model-sgl\", short=True)\n",
    "endpoint_config_name = model_name\n",
    "endpoint_name = model_name\n",
    "\n",
    "health_check_timeout = 600\n",
    "\n",
    "env = {\n",
    "    \"OPTION_MODEL\": model_id,\n",
    "    \"OPTION_CONTEXT_LENGTH\": \"32768\",\n",
    "    \"OPTION_TENSOR_PARALLEL_SIZE\": json.dumps(instance[\"num_gpu\"]),\n",
    "    \"OPTION_TOOL_CALL_PARSER\": \"qwen\",\n",
    "    \"OPTION_REASONING_PARSER\": \"qwen3\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1634e71f-a190-408f-bcb9-a314cd057e30",
   "metadata": {},
   "source": [
    "### Model -> Endpoint Config -> Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64cd9b-b418-49f6-aac5-8cda8740736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        \"Image\": inference_image,\n",
    "        \"Environment\": env,\n",
    "    }\n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf53e7e-a3f6-47aa-b116-149768c734ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants = [\n",
    "        {\n",
    "            \"VariantName\": \"alltraffic\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance[\"type\"],\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": health_check_timeout,\n",
    "            \"RoutingConfig\": {\n",
    "                'RoutingStrategy': 'LEAST_OUTSTANDING_REQUESTS'\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7fb065-9a37-4949-88e4-d3162c8cd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName = endpoint_name, EndpointConfigName = endpoint_config_name\n",
    ")\n",
    "sess.wait_for_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb4f2d-3bef-4913-8752-b51817441643",
   "metadata": {},
   "source": [
    "## Inference Test\n",
    "\n",
    "### Text inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c6a984-289d-44f2-9a42-5ecbf35744ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T20:13:20.100146Z",
     "iopub.status.busy": "2025-11-03T20:13:20.099890Z",
     "iopub.status.idle": "2025-11-03T20:13:32.097277Z",
     "shell.execute_reply": "2025-11-03T20:13:32.096800Z",
     "shell.execute_reply.started": "2025-11-03T20:13:20.100126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Response time: 11.99s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here's a curated list of **must-visit popular places in London**, balancing iconic landmarks, cultural treasures, and unique experiences, along with key details to help you plan:\n",
       "\n",
       "### üè∞ **Top 10 Iconic Landmarks & Must-Sees**\n",
       "1. **Buckingham Palace**  \n",
       "   *Why visit:* The official residence of the monarch. **Don't miss:** The **Changing of the Guard** (check schedule; every morning except Tuesdays). See the State Rooms (book *months* ahead) or the Queen's Gallery exhibitions.  \n",
       "   *Tip:* Free to view the exterior; gardens open seasonally.\n",
       "\n",
       "2. **The Tower of London**  \n",
       "   *Why visit:* Historic fortress, home to the Crown Jewels, and a site of royal executions. **Must-see:** The **Crown Jewels** (free entry with Tower ticket) and the chilling **Traitor's Gate**.  \n",
       "   *Tip:* Book tickets online to skip queues; allow 3‚Äì4 hours. *Note:* It's not \"Big Ben\" ‚Äì the tower is the **Elizabeth Tower** (housing the Great Bell).\n",
       "\n",
       "3. **London Eye**  \n",
       "   *Why visit:* Iconic 135m Ferris wheel on the South Bank with panoramic city views. **Best experience:** Sunset or evening rides (less crowded, lightsÁíÄÁí®).  \n",
       "   *Tip:* Book online for a timed entry; avoid peak hours (10 AM‚Äì3 PM).\n",
       "\n",
       "4. **Westminster Abbey**  \n",
       "   *Why visit:* Coronation church since 1066 (where Charles III was crowned). **Highlights:** Poets' Corner, the Coronation Chair, and the tomb of the Unknown Warrior.  \n",
       "   *Tip:* Book tickets early; join a guided tour to appreciate the history.\n",
       "\n",
       "5. **St. Paul's Cathedral**  \n",
       "   *Why visit:* Stunning Baroque architecture (wonder of Sir Christopher Wren). **Key moment:** Climb to the **Whispering Gallery** (acoustic trick!) or the **Golden Gallery** (360¬∞ views).  \n",
       "   *Tip:* Free entry; donations appreciated; avoid Sunday services if possible.\n",
       "\n",
       "### üé® **Cultural & Museum Highlights**\n",
       "6. **The British Museum**  \n",
       "   *Why visit:* One of the world's greatest museums (free entry!). **Must-see:** The Rosetta Stone, Parthenon Sculptures, and Egyptian mummies.  \n",
       "   *Tip:* Focus on 3‚Äì4 key galleries (e.g., Ancient Egypt, Mesopotamia) to avoid overwhelm.\n",
       "\n",
       "7. **National Gallery (Trafalgar Square)**  \n",
       "   *Why visit:* Home to 2,300+ European paintings (13th‚Äì19th century). **Highlights:** Van Gogh‚Äôs *Sunflowers*, da Vinci‚Äôs *The Virgin of the Rocks*, and Turner‚Äôs seascapes.  \n",
       "   *Tip:* Free entry; open until 8 PM on Wednesdays ‚Äì ideal for evening visits.\n",
       "\n",
       "8. **Tate Modern (Bankside)**  \n",
       "   *Why visit:* World‚Äôs largest modern art museum. **Standout:** The **Blind Light** exhibition space (spectacular views from the 10th floor).  \n",
       "   *Tip:* Free entry; the Turbine Hall installations change regularly (book timed tickets for busy days).\n",
       "\n",
       "### üå≥ **Green Spaces & Scenic Spots**\n",
       "9. **Hyde Park**  \n",
       "   *Why visit:* London‚Äôs largest royal park (142 hectares). **Key areas:** Serpentine Lake (rent a paddle boat), Speaker‚Äôs Corner (free speech tradition), and Kensington Gardens.  \n",
       "   *Tip:* Rent a bike or boat to explore; combine with nearby Kensington Palace.\n",
       "\n",
       "10. **Covent Garden**  \n",
       "    *Why visit:* Historic piazza with street performers, luxury shops, and vibrant dining. **Top stops:** Royal Opera House (tour), Neal‚Äôs Yard (colorful market), and the Apple Store‚Äôs dome.  \n",
       "    *Tip:* Visit early to avoid crowds; explore the hidden courtyards.\n",
       "\n",
       "### üí° **Pro Tips for Your Visit**\n",
       "- **Transport:** Use the **Tube** (Oyster/Contactless cards) ‚Äì avoid rush hour (7‚Äì10 AM, 4‚Äì7 PM).  \n",
       "- **Booking:** **Essential** for palace/tower visits (e.g., Tower of London, Buckingham Palace State Rooms).  \n",
       "- **Time Management:** Prioritize based on your interests:  \n",
       "  - *History buffs:* Tower of London, Westminster Abbey.  \n",
       "  - *Art lovers:* National Gallery, Tate Modern.  \n",
       "  - *Photographers:* London Eye (evening), St. Paul‚Äôs dome.  \n",
       "- **Hidden Gem:** **Notting Hill** (carnival in August, colorful streets) or **Camden Market** (edgy shopping, street food).  \n",
       "- **Avoid:** Overpaying for \"Big Ben\" photos ‚Äì the tower is *not* open to the public!  \n",
       "\n",
       "### üåÜ **Why London?**\n",
       "London‚Äôs magic lies in its **layered history** ‚Äì from Roman walls (Borough Market) to modern skyscrapers (The Shard). Pair iconic sights with local neighborhoods (like Brick Lane for curry, or the South Bank for street art) for a richer experience.  \n",
       "\n",
       "> ‚úÖ **Final advice:** Download the **Citymapper app** for real-time Tube routes, and wear **comfortable shoes** ‚Äì you‚Äôll walk 10+ miles!  \n",
       "\n",
       "Let me know if you'd like a **3-day itinerary**, **family-friendly options**, or **budget tips**! üòä"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "payload={\n",
    "    \"model\": model_id,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Name popular places to visit in London?\"}\n",
    "    ],\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "res = smr_client.invoke_endpoint(EndpointName = endpoint_name,\n",
    "                                 Body = json.dumps(payload),\n",
    "                                 ContentType = \"application/json\")\n",
    "response = json.loads(res[\"Body\"].read().decode(\"utf8\"))\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"‚úÖ Response time: {end_time-start_time:.2f}s\")\n",
    "display(Markdown(response[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534dc3f-0dec-4914-aeee-7d84fa1fc808",
   "metadata": {},
   "source": [
    "### Image Understanding\n",
    "\n",
    "Let's ask what is displayed on the image below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b273e395-74e3-4d41-bb03-a9945e3f83a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T20:13:41.447028Z",
     "iopub.status.busy": "2025-11-03T20:13:41.446773Z",
     "iopub.status.idle": "2025-11-03T20:13:41.450603Z",
     "shell.execute_reply": "2025-11-03T20:13:41.450162Z",
     "shell.execute_reply.started": "2025-11-03T20:13:41.447009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image as IPyImage\n",
    "IPyImage(url=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\", height=400, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a946d940-6660-471a-960f-4db02cee3f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T20:13:42.456745Z",
     "iopub.status.busy": "2025-11-03T20:13:42.456493Z",
     "iopub.status.idle": "2025-11-03T20:13:47.001318Z",
     "shell.execute_reply": "2025-11-03T20:13:47.000872Z",
     "shell.execute_reply.started": "2025-11-03T20:13:42.456724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Testing Image Understanding...\n",
      "‚úÖ Image Understanding Test Completed\n",
      "   Response Time: 4.54 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Image Analysis:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The image depicts a **Pallas‚Äôs cat** (also known as the *manul*), a small wild feline native to Central Asian grasslands and steppes, set against a wintry backdrop. Here‚Äôs a detailed breakdown:  \n",
       "\n",
       "### 1. The Animal (Pallas‚Äôs Cat)  \n",
       "- **Physical Appearance**:  \n",
       "  - It has a **stocky, compact body** with short legs, giving it a ‚Äúplump‚Äù silhouette.  \n",
       "  - Its **fur is thick and dense**, adapted for cold climates, with a mix of **tawny-brown, gray, and black hues**. Distinctive **dark stripes** run across its face (from the nose to the cheeks) and down its body, characteristic of the species.  \n",
       "  - Snow dusts its fur, especially on the back and head, indicating recent snowfall or a cold environment.  \n",
       "  - Its **face is round** with small, rounded ears, and its expression appears calm but alert. The eyes are partially squinted, possibly due to the cold or light.  \n",
       "  - One paw is lifted mid-step, suggesting movement across the snow.  \n",
       "\n",
       "- **Posture/Action**: The cat is walking on a snow-covered surface, with its body angled slightly to the left.  \n",
       "\n",
       "\n",
       "### 2. The Environment  \n",
       "- **Ground**: The surface is blanketed in **fresh, white snow**, with subtle texture variations (e.g., uneven patches, faint tracks). A small twig or piece of debris lies in the bottom-left corner of the snow.  \n",
       "- **Background**:  \n",
       "  - **Birch Trees**: Behind the cat, there are slender birch tree trunks with **pale white bark** marked by dark, irregular patches (typical of birch trees). Snow clings to the tree trunks, emphasizing the cold weather.  \n",
       "  - **Fence**: To the left, a **wire mesh fence** is visible, suggesting the scene might be in a controlled environment like a zoo or wildlife reserve (rather than a completely wild setting).  \n",
       "\n",
       "\n",
       "### 3. Atmosphere and Context  \n",
       "- The overall mood is **cold and serene**, conveyed by the snow, the cat‚Äôs thick fur, and the muted, wintry tones.  \n",
       "- The lighting is natural (likely daylight), with soft illumination that highlights the cat‚Äôs fur texture and the snow‚Äôs sheen.  \n",
       "\n",
       "\n",
       "This image captures the Pallas‚Äôs cat in its adapted, cold-climate habitat, emphasizing its unique physical traits and the wintry environment it inhabits."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üß™ Test 2: Image Understanding\n",
    "print(\"üñºÔ∏è Testing Image Understanding...\")\n",
    "\n",
    "image_request = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What do you see in this image? Describe it in detail.\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "res = smr_client.invoke_endpoint(EndpointName = endpoint_name,\n",
    "                                 Body = json.dumps(image_request),\n",
    "                                 ContentType = \"application/json\")\n",
    "response = json.loads(res[\"Body\"].read().decode(\"utf8\"))\n",
    "end_time = time.time()\n",
    "\n",
    "# Display results\n",
    "print(f\"‚úÖ Image Understanding Test Completed\")\n",
    "print(f\"   Response Time: {end_time - start_time:.2f} seconds\")\n",
    "print()\n",
    "\n",
    "# Render the response\n",
    "display(Markdown(\"**Image Analysis:**\"))\n",
    "display(Markdown(response[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ac93f3-254a-4a86-acb1-a81a22a5f6ca",
   "metadata": {},
   "source": [
    "### OCR example\n",
    "\n",
    "Re-using the example from this [repo](https://github.com/aws-samples/sample-qwen-on-aws/blob/main/Qwen3-VL/qwen3-vl-vllm-sagemaker-byoc/deploy_qwen3_vl_all_models.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33073a6c-271f-40cb-a1e0-9e14ee70acb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T20:13:51.677672Z",
     "iopub.status.busy": "2025-11-03T20:13:51.677285Z",
     "iopub.status.idle": "2025-11-03T20:13:51.682212Z",
     "shell.execute_reply": "2025-11-03T20:13:51.681754Z",
     "shell.execute_reply.started": "2025-11-03T20:13:51.677638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"invoice.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image as IPyImage\n",
    "IPyImage(url=\"invoice.png\", height=400, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e72f5b-8c42-4809-897c-383e2f0e05e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T20:13:54.173791Z",
     "iopub.status.busy": "2025-11-03T20:13:54.173529Z",
     "iopub.status.idle": "2025-11-03T20:14:02.044430Z",
     "shell.execute_reply": "2025-11-03T20:14:02.043925Z",
     "shell.execute_reply.started": "2025-11-03T20:13:54.173771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Testing OCR Capabilities...\n",
      "‚úÖ OCR Test Completed\n",
      "   Response Time: 7.86 seconds\n",
      "\n",
      "{\n",
      "  \"invoice_title\": \"INVOICE\",\n",
      "  \"issued_to\": {\n",
      "    \"name\": \"Richard Sanchez\",\n",
      "    \"company\": \"Thynk Unlimited\",\n",
      "    \"address\": \"123 Anywhere St., Any City\"\n",
      "  },\n",
      "  \"invoice_no\": \"01234\",\n",
      "  \"date\": \"11.02.2030\",\n",
      "  \"due_date\": \"11.03.2030\",\n",
      "  \"pay_to\": {\n",
      "    \"bank\": \"Borcele Bank\",\n",
      "    \"account_name\": \"Adeline Palmerston\",\n",
      "    \"account_no\": \"0123 4567 8901\"\n",
      "  },\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"description\": \"Brand consultation\",\n",
      "      \"unit_price\": \"100\",\n",
      "      \"qty\": \"1\",\n",
      "      \"total\": \"$100\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"logo design\",\n",
      "      \"unit_price\": \"100\",\n",
      "      \"qty\": \"1\",\n",
      "      \"total\": \"$100\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"Website design\",\n",
      "      \"unit_price\": \"100\",\n",
      "      \"qty\": \"1\",\n",
      "      \"total\": \"$100\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"Social media templates\",\n",
      "      \"unit_price\": \"100\",\n",
      "      \"qty\": \"1\",\n",
      "      \"total\": \"$100\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"Brand photography\",\n",
      "      \"unit_price\": \"100\",\n",
      "      \"qty\": \"1\",\n",
      "      \"total\": \"$100\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"Brand guide\",\n",
      "      \"unit_price\": \"100\",\n",
      "      \"qty\": \"1\",\n",
      "      \"total\": \"$100\"\n",
      "    }\n",
      "  ],\n",
      "  \"subtotal\": \"$400\",\n",
      "  \"tax\": \"10%\",\n",
      "  \"total\": \"$440\",\n",
      "  \"signature\": \"Adeline Palmerston\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# üß™ Test 3: OCR Capabilities\n",
    "print(\"üìä Testing OCR Capabilities...\")\n",
    "\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to encode image to base64\n",
    "def encode_image_to_base64(image_path: str) -> str:\n",
    "    \"\"\"Encode an image file to base64 string.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "# Encode the image\n",
    "image_path = \"invoice.png\"\n",
    "if Path(image_path).exists():\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "\n",
    "    local_image_request = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Extract all the text you can read from this image, and generate response in JSON format\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "\n",
    "    # Measure inference time\n",
    "    # Measure inference time\n",
    "    start_time = time.time()\n",
    "    res = smr_client.invoke_endpoint(EndpointName = endpoint_name,\n",
    "                                     Body = json.dumps(local_image_request),\n",
    "                                     ContentType = \"application/json\")\n",
    "    response = json.loads(res[\"Body\"].read().decode(\"utf8\"))\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Display results\n",
    "    print(f\"‚úÖ OCR Test Completed\")\n",
    "    print(f\"   Response Time: {end_time - start_time:.2f} seconds\")\n",
    "    print()\n",
    "\n",
    "    # Print the response\n",
    "    print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Image file not found. Please provide a valid image path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece46aca-c35f-44c9-9887-90982cd30c8b",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "654b369f-8f8d-4039-baed-9f2206fdd32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T20:14:11.494965Z",
     "iopub.status.busy": "2025-11-03T20:14:11.494713Z",
     "iopub.status.idle": "2025-11-03T20:14:12.086994Z",
     "shell.execute_reply": "2025-11-03T20:14:12.086486Z",
     "shell.execute_reply.started": "2025-11-03T20:14:11.494945Z"
    }
   },
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_config_name)\n",
    "sess.delete_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2401dac-bfb5-4193-a1e8-10b3ff415565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
