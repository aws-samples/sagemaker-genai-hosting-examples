{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993dcf59-dd85-4a31-a8cc-02c5d4be5dfe",
   "metadata": {},
   "source": [
    "# Build and push custom container to ECR using Amazon SageMaker AI Studion v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef819c-5aff-4e14-a07d-27c227204560",
   "metadata": {},
   "source": [
    "In this notebook we build and push into Amazon ECR custom container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be5a22",
   "metadata": {},
   "source": [
    "## Prepare the SGLang SageMaker container\n",
    "\n",
    "SageMaker AI makes extensive use of¬†Docker containers¬†for build and runtime tasks. Using containers, you can train machine learning algorithms and deploy models quickly and reliably at any scale. See [this link](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-code-run-image) to understand how SageMaker AI runs your inference image. \n",
    "\n",
    "- For model inference, SageMaker AI runs the container as:\n",
    "```\n",
    "docker run image serve\n",
    "```\n",
    "\n",
    "- You can provide your entrypoint script as `exec` form to provide instruction of how to perform the inference process, for example:\n",
    "```\n",
    "ENTRYPOINT [\"python\", \"inference.py\"]\n",
    "```\n",
    "\n",
    "- When deploying ML models, one option is to archive and compress the model artifacts into a `tar.gz` format and provided the s3 path of the model artifacts as the `ModelDataUrl` in the [`CreateModel`](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateModel.html) API request. SageMaker AI will copy the model artifacts from the S3 location \n",
    " and decompresses this tar file into `/opt/ml/model` directory before your container starts for use by your inference code. However, for deploying large models, SageMaker AI allows you to [deploy uncompressed models](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-uncompressed.html). In this example, we will show you how to use the uncompressed DeepSeek R1 Distilled Llama 70B model.\n",
    "\n",
    "- To receive inference requests, the container must have a web server listening on port `8080` and must accept `POST` requests to the `/invocations` and `/ping` endpoints.\n",
    "\n",
    "If you already have a docker image, you can see more instructions for [adapting your own inference container for SageMaker AI](https://docs.aws.amazon.com/sagemaker/latest/dg/adapt-inference-container.html). Also it is important to note that, SageMaker AI provided containers automatically implements a web server for serving requests that responds to `/invocations` and `/ping` (for healthcheck) requests. You can find more about the [prebuilt SageMaker AI docker images for deep learning in our SageMaker doc](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a1755-ddcb-416c-aa74-33920280fed2",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "Fetch and import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86f277-cd24-455d-972a-ed63a86b93b2",
   "metadata": {},
   "source": [
    "Container preparation:\n",
    "\n",
    "    Enable Docker access in your Studio domain.\n",
    "    Install Docker in your Studion environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4039c65-7c85-496b-9f4e-9b7d29bacdb5",
   "metadata": {},
   "source": [
    "## Build and push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988924be-00de-47a0-b897-7c612250609d",
   "metadata": {},
   "source": [
    "### Check if Docker is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7246627-0df7-4326-91ce-4a9db828a8cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T19:22:42.929625Z",
     "iopub.status.busy": "2025-11-02T19:22:42.929284Z",
     "iopub.status.idle": "2025-11-02T19:22:42.952562Z",
     "shell.execute_reply": "2025-11-02T19:22:42.952079Z",
     "shell.execute_reply.started": "2025-11-02T19:22:42.929592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker already installed: Docker version unknown-version, build unknown-commit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install Docker in SageMaker Studio\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def check_docker():\n",
    "    \"\"\"Install Docker in SageMaker Studio following AWS guidelines\"\"\"\n",
    "    try:\n",
    "        # Check if Docker is already installed\n",
    "        result = subprocess.run(['docker', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"Docker already installed: {result.stdout.strip()}\")\n",
    "            return True\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "# Check if Docker is installed\n",
    "check_docker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86097fe1-5779-42f5-87b2-f1cb67c7d285",
   "metadata": {},
   "source": [
    "** Uncomment and run the next line if Docker is not istalled ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f67e9-a654-4b31-ad33-31bf321b8684",
   "metadata": {},
   "outputs": [],
   "source": [
    "!install_docker_sagemaker.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b070f66-bbe8-4f6b-8143-190a36bf31e0",
   "metadata": {},
   "source": [
    "### Build and push the container\n",
    "\n",
    "Please change the values for `TAG` and `SRC_TAG` accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b18a7-c0be-4ab0-8fa1-be907ab959f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./build.sh\n",
    "#!/bin/bash\n",
    "\n",
    "# Build and Push Custom SGLang Container to Amazon ECR\n",
    "\n",
    "set -e\n",
    "\n",
    "# Configuration\n",
    "AWS_REGION=${AWS_DEFAULT_REGION:-us-east-1}\n",
    "AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\n",
    "REPOSITORY_NAME=\"sglang\"\n",
    "TAG=v0.5.4\n",
    "SRC_TAG=v0.5.4.post1\n",
    "IMAGE_URI=\"${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPOSITORY_NAME}:${TAG}\"\n",
    "\n",
    "echo \"Repository: ${REPOSITORY_NAME}\"\n",
    "echo \"Image URI: ${IMAGE_URI}\"\n",
    "echo \"Region: ${AWS_REGION}\"\n",
    "\n",
    "# Step 1: Create ECR repository if it doesn't exist\n",
    "echo \"üì¶ Creating ECR repository if it doesn't exist...\"\n",
    "aws ecr describe-repositories --repository-names ${REPOSITORY_NAME} --region ${AWS_REGION} 2>/dev/null || \\\n",
    "aws ecr create-repository --repository-name ${REPOSITORY_NAME} --region ${AWS_REGION}\n",
    "\n",
    "# Step 2: Get ECR login token\n",
    "echo \"üîê Logging into Amazon ECR...\"\n",
    "aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com\n",
    "\n",
    "# Step 3: Build the Docker image\n",
    "echo \"üî® Building Docker image for SQLang...\"\n",
    "docker build . --tag ${REPOSITORY_NAME}:${TAG} --file Dockerfile --build-arg BASE_IMAGE=lmsysorg/sglang:${SRC_TAG}\n",
    "\n",
    "# Step 4: Tag the image for ECR\n",
    "echo \"üè∑Ô∏è   Tagging image for ECR...\"\n",
    "docker tag ${REPOSITORY_NAME}:${TAG} ${IMAGE_URI}\n",
    "\n",
    "# Step 5: Push the image to ECR\n",
    "echo \"‚¨ÜÔ∏è  Pushing image to ECR...\"\n",
    "docker push ${IMAGE_URI}\n",
    "\n",
    "echo \"‚úÖ Successfully built and pushed custom SGLang container!\"\n",
    "echo \"Image URI: ${IMAGE_URI}\"\n",
    "echo \"\"\n",
    "echo \"You can now use this image URI in your SageMaker deployment:\"\n",
    "echo \"image_uri = \\\"${IMAGE_URI}\\\"\"\n",
    "\n",
    "# Optional: Clean up local images to save space\n",
    "read -p \"üóëÔ∏è   Clean up local Docker images? (y/N): \" -n 1 -r\n",
    "echo\n",
    "if [[ $REPLY =~ ^[Yy]$ ]]; then\n",
    "    echo \"üßπ Cleaning up local images...\"\n",
    "    docker rmi ${REPOSITORY_NAME}:${TAG} ${IMAGE_URI}\n",
    "    echo \"Local images cleaned up\"\n",
    "fi\n",
    "\n",
    "echo \"üéâ Build and push completed successfully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af4d9f-8757-4d84-99f8-e8348ad015d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./build.sh;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9127a5-b04d-4d72-bcdb-8c03bc66d6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
