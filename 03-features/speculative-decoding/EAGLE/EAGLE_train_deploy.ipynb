{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993dcf59-dd85-4a31-a8cc-02c5d4be5dfe",
   "metadata": {},
   "source": [
    "# Gwen3-1.7B EAGLE head\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Train EAGLE3 head for [Gwen3-1.7b](https://huggingface.co/Qwen/Qwen3-1.7B) model using Amazon SageMaker AI optimization job\n",
    "2. Deploy `Gwen3-1.7B` model with EAGLE3-based speculative decoding\n",
    "\n",
    "\n",
    "For more information, please refer to this [blog](https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-ai-introduces-eagle-based-adaptive-speculative-decoding-to-accelerate-generative-ai-inference/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef2756ce-9830-4e4c-afe5-69c9da0368fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet --no-warn-conflicts boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9183bf15-3f3f-4d70-91da-fe269ff421b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import boto3\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "sm = boto3.client(\"sagemaker\")  # client to intreract with SageMaker\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")  # client to intreract with SageMaker Endpoints\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d0b3e-0901-44c3-8047-6efc650f0827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Helper functions to remove dependency on SageMaker Python SDK\n",
    "#\n",
    "def get_sagemaker_role():\n",
    "    sts = boto3.client('sts')\n",
    "    response = sts.get_caller_identity()\n",
    "    assumed_role = response['Arn']\n",
    "    role = re.sub(r\"^(.+)sts::(\\d+):assumed-role/(.+?)/.*$\", r\"\\1iam::\\2:role/\\3\", assumed_role)\n",
    "    return role\n",
    "\n",
    "\n",
    "def wait_for_endpoint(endpoint_name: str, sleep_time: int = 60):\n",
    "    ind = \".\"\n",
    "    progress = f\"Waiting for '{endpoint_name}': \"\n",
    "    print(progress)\n",
    "\n",
    "    status = sm.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "\n",
    "    while status == \"Creating\":\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "        status = sm.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        progress += ind\n",
    "        print(progress)\n",
    "\n",
    "    print(f\"Endpoint: '{endpoint_name}', Status: '{status}'\")\n",
    "\n",
    "def wait_for_ic(ic_name: str, sleep_time: int = 60):\n",
    "    ind = \".\"\n",
    "    progress = f\"Waiting for '{ic_name}': \"\n",
    "    print(progress)\n",
    "\n",
    "    status = sm.describe_inference_component(InferenceComponentName = ic_name)[\"InferenceComponentStatus\"]\n",
    "\n",
    "    while status == \"Creating\":\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "        status = sm.describe_inference_component(InferenceComponentName = ic_name)[\"InferenceComponentStatus\"]\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        progress += ind\n",
    "        print(progress)\n",
    "\n",
    "    print(f\"IC: '{ic_name}', Status: '{status}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6549e-00c6-4db8-a9de-5dfb2e0f6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Overwrite with your role ARN if you are running this notebook outside of SageMaker Studio\n",
    "#\n",
    "role = None\n",
    "\n",
    "if role == None:\n",
    "    role = get_sagemaker_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af46c0-888d-4583-bc4b-d0dd9bcf46bc",
   "metadata": {},
   "source": [
    "## Model and dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26006a46-3e39-4fac-9928-288f2a34fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen3-1.7B\"\n",
    "bucket = \"<YOUR_BUCKET>\"\n",
    "model_s3_key = f\"model/{model_id}\"\n",
    "dataset_file = \"gsm8k_200.jsonl\"\n",
    "dataset_s3_key = f\"training-data/gsm8k200/{dataset_file}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5debc2b",
   "metadata": {},
   "source": [
    "We will download the model (`Qwen3-1.7B`) from the HuggingFace hub and upload the model weights to Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db8976-2718-491d-a32b-90bb236159b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_path = Path(\"./data\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "\n",
    "snapshot_download(repo_id=model_id, local_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9ce44-1491-4c9f-bf16-f73b765b4939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate local files recursively\n",
    "for root, dirs, files in os.walk(local_model_path):\n",
    "    for filename in files:\n",
    "        local_path = os.path.join(root, filename)\n",
    "\n",
    "        relative_path = os.path.relpath(local_path, local_model_path)\n",
    "        s3_path = os.path.join(model_s3_key, relative_path)\n",
    "\n",
    "        print(\"Uploading %s...\" % s3_path)\n",
    "        s3.upload_file(local_path, bucket, s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4ab9f5-b905-4d20-9ccf-fd0b08f9b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(dataset_file, bucket, dataset_s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b1bca6-9f60-4c5f-983f-7d69f244981e",
   "metadata": {},
   "source": [
    "## Optimization Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3607a04e-4f3b-41aa-b56d-265c902c3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = f\"s3://{bucket}/{model_s3_key}/\"\n",
    "training_data = f\"s3://{bucket}/training-data/gsm8k200/\"\n",
    "output_data = f\"s3://{bucket}/{model_s3_key}-gsm200-eagle/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605043b-b3b2-48f1-b038-85cc8a1cee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f\"opt-{time.strftime('%y%m%d-%H%M%S')}\"\n",
    "\n",
    "opt_job = sm.create_optimization_job(\n",
    "    OptimizationJobName=job_name,\n",
    "    RoleArn=role,\n",
    "    ModelSource={\n",
    "        'S3': {\n",
    "            'S3Uri': base_model,\n",
    "        }\n",
    "    },\n",
    "    DeploymentInstanceType='ml.g6.24xlarge',\n",
    "    MaxInstanceCount=1,\n",
    "    OptimizationConfigs=[\n",
    "        {\n",
    "            'ModelSpeculativeDecodingConfig': {\n",
    "                'Technique': 'EAGLE',\n",
    "                'TrainingDataSource': {\n",
    "                    'S3Uri': training_data,\n",
    "                    'S3DataType': 'S3Prefix'\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': output_data,\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 432000,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(json.dumps(opt_job, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533a6296-f0bc-416c-a03b-012362488bf5",
   "metadata": {},
   "source": [
    "**PLEASE NOTE THE JOB WILL TAKE ABOUT 2 HOURS TO COMPLETE**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b460f-5b16-4e08-adfc-74708e7c7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_status = sm.describe_optimization_job(\n",
    "    OptimizationJobName=job_name\n",
    ")\n",
    "job_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e3a3ef-99a6-473b-9818-37df3e130fd5",
   "metadata": {},
   "source": [
    "\n",
    "**After the optimization job completes, you can access evaluation results and draft model weights in the output S3 path**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07d0b920-2699-4ee4-abc6-6bf09e389e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE draft/\n",
      "                           PRE opt-260123-164926-48bf6945-5af6-42ea-92e1-61172fe33d42-4-of-4/\n",
      "                           PRE results/\n",
      "------\n",
      "2026-01-23 16:49:37        862 config.json\n",
      "2026-01-23 18:29:31  286614232 model.safetensors\n",
      "------\n",
      "2026-01-23 18:58:03       1380 benchmark_no_eagle_conc1.json\n",
      "2026-01-23 18:58:03       1375 benchmark_no_eagle_conc16.json\n",
      "2026-01-23 18:58:03       1376 benchmark_no_eagle_conc2.json\n",
      "2026-01-23 18:58:03       1374 benchmark_no_eagle_conc4.json\n",
      "2026-01-23 18:58:03       1376 benchmark_no_eagle_conc8.json\n",
      "2026-01-23 18:58:03     250508 benchmark_report.html\n",
      "2026-01-23 18:58:03       1384 benchmark_trained_eagle_conc1.json\n",
      "2026-01-23 18:58:03       1374 benchmark_trained_eagle_conc16.json\n",
      "2026-01-23 18:58:03       1382 benchmark_trained_eagle_conc2.json\n",
      "2026-01-23 18:58:03       1372 benchmark_trained_eagle_conc4.json\n",
      "2026-01-23 18:58:03       1381 benchmark_trained_eagle_conc8.json\n"
     ]
    }
   ],
   "source": [
    "results = f\"{output_data}results/\"\n",
    "draft_model_path = f\"{output_data}draft/\"\n",
    "!aws s3 ls $output_data\n",
    "!echo '------'\n",
    "!aws s3 ls $draft_model_path\n",
    "!echo '------'\n",
    "!aws s3 ls $results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01ea7d-aa6b-43a4-8fab-473538be46ca",
   "metadata": {},
   "source": [
    "**Here is snippet of the report**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a5ed5a-f674-4e52-acff-438c3f57f55b",
   "metadata": {},
   "source": [
    "![title](results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdb7fb-319f-4db9-92ea-0c7a94212365",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "We are going to use LMIv18 container, see [this](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers) for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91002f-04c1-450f-a414-ea262870a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER_VERSION = \"0.36.0-lmi18.0.0-cu128\"\n",
    "inference_image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:{CONTAINER_VERSION}\"\n",
    "\n",
    "instance = {\"type\": \"ml.g5.2xlarge\", \"num_gpu\": 1}\n",
    "\n",
    "model_id = base_model\n",
    "channel_name = \"eagle\"\n",
    "\n",
    "model_name = f\"model-{time.strftime('%y%m%d-%H%M%S')}\"\n",
    "endpoint_name = model_name\n",
    "endpoint_config_name = model_name\n",
    "timeout = 600\n",
    "\n",
    "variant_name = \"main\"\n",
    "\n",
    "spec_config = {\n",
    "    \"method\": \"eagle3\",\n",
    "    \"model\": f\"/opt/ml/additional-model-data-sources/{channel_name}\",\n",
    "    \"draft_tensor_parallel_size\": 1,\n",
    "    \"num_speculative_tokens\": 5\n",
    "}\n",
    "\n",
    "lmi_env = {\n",
    "    \"OPTION_MODEL\": \"/opt/ml/model\",\n",
    "    \"SERVING_FAIL_FAST\": \"true\",\n",
    "    \"OPTION_ASYNC_MODE\": \"true\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "    \"OPTION_TENSOR_PARALLEL_DEGREE\": json.dumps(instance[\"num_gpu\"]),\n",
    "    \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "    \"OPTION_MAX_MODEL_LEN\": \"16384\",\n",
    "    \"OPTION_SPECULATIVE_CONFIG\": json.dumps(spec_config),\n",
    "}\n",
    "env = lmi_env\n",
    "\n",
    "model_data_source = {\n",
    "    'S3DataSource': {\n",
    "        'S3Uri': model_id,\n",
    "        'S3DataType': 'S3Prefix',\n",
    "        'CompressionType': 'None',\n",
    "    }\n",
    "}\n",
    "\n",
    "add_data_source = {\n",
    "    'ChannelName': channel_name,\n",
    "    'S3DataSource': {\n",
    "        'S3Uri': draft_model_path,\n",
    "        'S3DataType': 'S3Prefix',\n",
    "        'CompressionType': 'None',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64cd9b-b418-49f6-aac5-8cda8740736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = sm.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        \"Image\": inference_image,\n",
    "        \"Environment\": env,\n",
    "        \"ModelDataSource\": model_data_source,\n",
    "        \"AdditionalModelDataSources\": [add_data_source],\n",
    "    },\n",
    ")\n",
    "print(json.dumps(model_res, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf53e7e-a3f6-47aa-b116-149768c734ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 'model-260123-202533': ..........\n",
      "Endpoint: 'model-260123-202533', Status: 'InService'\n"
     ]
    }
   ],
   "source": [
    "config_res = sm.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants = [\n",
    "        {\n",
    "            \"VariantName\": variant_name,\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance[\"type\"],\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": timeout,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "endpoint_res = sm.create_endpoint(EndpointName = endpoint_name,\n",
    "                                  EndpointConfigName = endpoint_config_name)\n",
    "\n",
    "_ = wait_for_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a5ff8b-8c11-405c-8ce6-77ebdac244c7",
   "metadata": {},
   "source": [
    "### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6a984-289d-44f2-9a42-5ecbf35744ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Response time: 32.00s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, the user is asking for popular places to visit in London. Let me start by recalling the main attractions. London is a big city with a lot of iconic spots. First, the Tower of London comes to mind. It's a historic site with the Crown Jewels and the Tower Museum. Then there's the British Museum, which is a must-see for its vast collection of art and artifacts.\n",
       "\n",
       "I should also mention the Westminster Abbey, which is a famous religious site and a symbol of the UK's monarchy. The London Eye is another big one, offering a panoramic view of the city. The British Museum is definitely a top spot, but maybe the National Gallery is also popular. Oh, and the Houses of Parliament and Big Ben are iconic landmarks.\n",
       "\n",
       "Wait, the user might be interested in both historical and modern attractions. So I need to balance between old and new. The Shard is a modern skyscraper, and the London Eye is a modern landmark. Also, the Thames River is a big part of London's identity, so mentioning places along the river like the Tate Modern or the London Bridge could be useful.\n",
       "\n",
       "I should also think about tourist attractions that are family-friendly or have unique experiences. The London Zoo is a good one, but maybe the Science Museum is another option. Oh, and the Tower of London is a bit of a must-visit, but sometimes people might not know about the nearby places like the National Gallery. Let me check if there are any other major attractions I'm missing. The Globe Theatre, the Natural History Museum, and the Victoria and Albert Museum are also popular. \n",
       "\n",
       "I need to make sure the list is comprehensive but not too long. Maybe group them into categories like historical sites, museums, modern landmarks, and natural attractions. Also, include some popular areas like the West End for theaters and shopping. Oh, and the City of London and the East End have different attractions. The East End has places like the South Bank and the Barbican. \n",
       "\n",
       "Wait, the user might not be familiar with the East End, so maybe mention that as a separate section. Also, the British Museum is in the South Bank, so that's a good point. I should also note that some places are closed during certain times, like the National Gallery during exhibitions, so maybe mention that. \n",
       "\n",
       "I should structure the answer in a way that's easy to follow, maybe with headings for each category. Make sure the names are correct and the descriptions are accurate. Avoid any outdated information. Check if the London Eye is considered a popular place, and if the Tower of London is still a top attraction. Also, mention the Royal Albert Hall for music events. \n",
       "\n",
       "Okay, putting it all together, the answer should list the main attractions with brief descriptions, maybe a few bullet points, and ensure it's clear and helpful for the user.\n",
       "</think>\n",
       "\n",
       "London is a vibrant city with a rich history, stunning architecture, and a wealth of cultural attractions. Here are some of the most popular places to visit:\n",
       "\n",
       "### **Historical & Cultural Sites**  \n",
       "1. **Tower of London**  \n",
       "   - A medieval fortress with the Crown Jewels, the Crown Jewels Museum, and the Royal Mint.  \n",
       "   - Explore its history, including the Black Death and the Tower's role in the English monarchy.  \n",
       "\n",
       "2. **British Museum**  \n",
       "   - One of the worldâ€™s largest and most comprehensive art museums, housing artifacts from around the globe.  \n",
       "   - Must-see: The Rosetta Stone, the Egyptian collection, and the Hall of Bulls.  \n",
       "\n",
       "3. **Westminster Abbey**  \n",
       "   - A Gothic masterpiece, home to the Crown Jewels and the Abbeyâ€™s famous choir.  \n",
       "   - A symbol of the UKâ€™s monarchy and a site for weddings and royal events.  \n",
       "\n",
       "4. **The Houses of Parliament**  \n",
       "   - The iconic **Big Ben** (the clock tower) and the **Palace of Westminster**.  \n",
       "   - Visit the National Gallery and the British Library nearby.  \n",
       "\n",
       "### **Modern & Iconic Landmarks**  \n",
       "5. **London Eye**  \n",
       "   - A 135-meter observation wheel offering panoramic views of the city.  \n",
       "   - A popular spot for photos and night views.  \n",
       "\n",
       "6. **The Shard**  \n",
       "   - A 310-meter skyscraper with a rooftop restaurant and a 360Â° view of London.  \n",
       "\n",
       "7. **The London Eye**  \n",
       "   - A 135-meter observation wheel offering panoramic views of the city.  \n",
       "\n",
       "8. **The National Gallery**  \n",
       "   - A world-renowned art museum with masterpieces by Van Gogh, Rembrandt, and Leonardo da Vinci.  \n",
       "\n",
       "### **Natural & Leisure Attractions**  \n",
       "9. **Tate Modern**  \n",
       "   - A contemporary art museum located on the banks of the Thames, featuring works by contemporary artists.  \n",
       "\n",
       "10. **The Thames River**  \n",
       "    - Explore the River Thames, with landmarks like **London Bridge**, **Tower Bridge**, and **The South Bank**.  \n",
       "\n",
       "11. **The London Eye**  \n",
       "    - A 135-meter observation wheel offering panoramic views of the city.  \n",
       "\n",
       "12. **The London Zoo**  \n",
       "    - A wildlife sanctuary with a variety of animals and a scenic garden.  \n",
       "\n",
       "### **Other Must-Visit Areas**  \n",
       "- **The East End** (e.g., **South Bank**, **Barbican**, **The Royal Academy**)  \n",
       "- **The Science Museum** (for interactive exhibits)  \n",
       "- **The Royal Albert Hall** (for concerts and music events)  \n",
       "- **The National Archives** (for historical documents)  \n",
       "\n",
       "### Tips:  \n",
       "- Check opening hours and ticket availability for major attractions.  \n",
       "- Use apps like **Google Maps** or **Walking Tours** for guided itineraries.  \n",
       "\n",
       "Londonâ€™s mix of history, art, and modernity makes it a must-visit for travelers! ðŸŒŸ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "{'prompt_tokens': 16, 'total_tokens': 1228, 'completion_tokens': 1212, 'prompt_tokens_details': None}\n"
     ]
    }
   ],
   "source": [
    "payload={\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Name popular places to visit in London?\"}\n",
    "    ],\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "res = sm_runtime.invoke_endpoint(EndpointName = endpoint_name,\n",
    "                                 Body = json.dumps(payload),\n",
    "                                 ContentType = \"application/json\")\n",
    "response = json.loads(res[\"Body\"].read().decode(\"utf8\"))\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"âœ… Response time: {end_time-start_time:.2f}s\\n\")\n",
    "display(Markdown(response[\"choices\"][0][\"message\"][\"content\"]))\n",
    "\n",
    "usage = response[\"usage\"]\n",
    "print(f'-----------------------\\n{usage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e0405-fd55-40cc-b3fc-8cdb2949f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class LineIterator:\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line)\n",
    "                return line[:-1]\n",
    "            try:\n",
    "                chunk = next(self.byte_iterator)\n",
    "            except StopIteration:\n",
    "                if self.read_pos < self.buffer.getbuffer().nbytes:\n",
    "                    continue\n",
    "                raise\n",
    "            if \"PayloadPart\" not in chunk:\n",
    "                print(\"Unknown event type:\" + chunk)\n",
    "                continue\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk[\"PayloadPart\"][\"Bytes\"])\n",
    "\n",
    "def stream_response(endpoint_name, inputs, max_tokens=8189, temperature=0.7, top_p=0.9):\n",
    "    body = {\n",
    "      \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": inputs}]}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"stream\": True,\n",
    "    }\n",
    "\n",
    "    resp = sm_runtime.invoke_endpoint_with_response_stream(\n",
    "        EndpointName = endpoint_name,\n",
    "        Body = json.dumps(body),\n",
    "        ContentType = \"application/json\",\n",
    "    )\n",
    "\n",
    "    event_stream = resp[\"Body\"]\n",
    "    start_json = b\"{\"\n",
    "    full_response = \"\"\n",
    "    start_time = time.time()\n",
    "    token_count = 0\n",
    "\n",
    "    for line in LineIterator(event_stream):\n",
    "        if line != b\"\" and start_json in line:\n",
    "            data = json.loads(line[line.find(start_json):].decode(\"utf-8\"))\n",
    "            token_text = data['choices'][0]['delta'].get('content', '')\n",
    "            full_response += token_text\n",
    "            token_count += 1\n",
    "\n",
    "            # Calculate tokens per second\n",
    "            elapsed_time = time.time() - start_time\n",
    "            tps = token_count / elapsed_time if elapsed_time > 0 else 0\n",
    "\n",
    "            # Clear the output and reprint everything\n",
    "            clear_output(wait=True)\n",
    "            print(full_response)\n",
    "            print(f\"\\nTokens per Second: {tps:.2f}\", end=\"\")\n",
    "\n",
    "    print(\"\\n\") # Add a newline after response is complete\n",
    "\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fcfee06-4a1a-40f7-94e5-07032a19b6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out whether 9.11 is greater than 9.8 or not. Let me think. Both numbers are decimals, right? So they have whole numbers and decimal parts. Let me write them down again to visualize better: 9.11 and 9.8. \n",
      "\n",
      "First, I remember that when comparing decimals, you start by looking at the digits from left to right. So, both numbers have the same whole number part, which is 9. That's easy. Now, the next part is the decimal part. \n",
      "\n",
      "For 9.11, the decimal part is 0.11, and for 9.8, it's 0.8. So, comparing the decimal parts. Let's break it down. The first decimal place is tenths. 9.11 has 1 in the tenths place, and 9.8 has 8 in the tenths place. Since 1 is less than 8, that would mean that 0.11 is less than 0.8. Therefore, 9.11 is less than 9.8. \n",
      "\n",
      "Wait, but maybe I should check if there's any other way to compare them. For example, converting them into fractions. Let me try that. 9.11 is the same as 9 + 0.11, and 9.8 is 9 + 0.8. So, subtracting the whole numbers, they are both 9, so the difference is in the decimal parts. 0.11 vs. 0.8. As before, 0.11 is smaller than 0.8. Therefore, 9.11 is smaller. \n",
      "\n",
      "Another way: think about moving the decimal places. If I multiply both numbers by 100 to eliminate the decimals, 9.11 becomes 911 and 9.8 becomes 980. Now, comparing 911 and 980. Since 911 is less than 980, that means 9.11 is less than 9.8. \n",
      "\n",
      "Hmm, so all these methods are pointing towards the same conclusion. But maybe I should check if I made any mistakes in the decimal places. For instance, 9.11 is 9.11, and 9.8 is 9.80. So, when comparing 9.11 and 9.80, the first decimal place is 1 vs. 8. Since 1 < 8, 9.11 is less than 9.80. \n",
      "\n",
      "Wait, but sometimes when people write decimals, they might have different numbers of decimal places. But in this case, 9.11 has two decimal places, and 9.8 has one. So, to compare them, it's better to convert them to have the same number of decimal places. So, 9.8 can be written as 9.80, and then compare 9.11 vs. 9.80. \n",
      "\n",
      "Yes, so 9.11 is 9.11 and 9.80 is 9.80. So, 9.11 is less than 9.80. Therefore, 9.11 is not greater than 9.8. \n",
      "\n",
      "I think that's solid. Let me think if there's any other angle. For example, rounding. If I round 9.11 up to the nearest tenth, it would be 9.1, and 9.8 is already 9.8. So, 9.1 is less than 9.8. So that also supports the conclusion. \n",
      "\n",
      "Alternatively, if I think about the decimal places as positions. The tenths place is the first digit after the decimal. 9.11 is 9.11, so the tenths place is 1, and the hundredths place is 1. 9.8 is 9.80, so the tenths place is 8, and the hundredths place is 0. So, comparing the tenths place first: 1 vs. 8. Since 1 is less than 8, the entire number is less. \n",
      "\n",
      "Yes, that's the standard way of comparing decimals. So, the answer is that 9.11 is less than 9.8. Therefore, 9.8 is greater than 9.11. \n",
      "\n",
      "I don't think I made any mistakes here. All the methods I tried lead to the same conclusion. So, I'm confident that 9.8 is greater than 9.11.\n",
      "</think>\n",
      "\n",
      "To determine whether **9.11** is greater than **9.8**, we compare the two numbers digit by digit, starting from the left.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Compare the Whole Number Parts\n",
      "\n",
      "Both numbers have the same whole number part: **9**.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 2: Compare the Decimal Parts\n",
      "\n",
      "Now, we look at the **decimal parts**:\n",
      "\n",
      "- **9.11** has a decimal part of **0.11**\n",
      "- **9.8** has a decimal part of **0.8**\n",
      "\n",
      "We compare the **tenths** place first:\n",
      "\n",
      "- The tenths digit of **9.11** is **1**\n",
      "- The tenths digit of **9.8** is **8**\n",
      "\n",
      "Since **1 < 8**, the decimal part of **9.11** is smaller than that of **9.8**.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 3: Conclusion\n",
      "\n",
      "Because the tenths place of **9.11** is smaller than that of **9.8**, **9.11 < 9.8**.\n",
      "\n",
      "---\n",
      "\n",
      "### Final Answer:\n",
      "\n",
      "$$\n",
      "\\boxed{9.8 \\text{ is greater than } 9.11}\n",
      "$$\n",
      "\n",
      "Tokens per Second: 28.64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = \"What is greater 9.11 or 9.8?\"\n",
    "output = stream_response(endpoint_name, inputs, max_tokens=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece46aca-c35f-44c9-9887-90982cd30c8b",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "654b369f-8f8d-4039-baed-9f2206fdd32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "_ = sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "_ = sm.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2401dac-bfb5-4193-a1e8-10b3ff415565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
