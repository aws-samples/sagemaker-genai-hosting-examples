{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21fd137c",
   "metadata": {},
   "source": [
    "# Amazon Nova Models on SageMaker Inference End-to-End Runbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820b1df",
   "metadata": {},
   "source": [
    "## 0. Update Credential\n",
    "\n",
    "**Note**:\n",
    "This section needs to be updated to reflect customers' account credential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef126a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/12/02 02:56:05 Successfully refreshed aws credentials for default\n",
      "✓ Fresh credentials loaded: 618100645563\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# AWS Configuration - Update these for your environment\n",
    "REGION = \"us-east-1\"  # Change to your preferred region\n",
    "AWS_ACCOUNT_ID = \"YOUR_ACCOUNT_ID\"  # Replace with your AWS account ID\n",
    "\n",
    "# CREDENTIAL SETUP OPTIONS:\n",
    "# Option 1. AWS CLI: Run 'aws configure' and enter your access key, secret key, and region\n",
    "# Option 2. Credentials file: Create ~/.aws/credentials with:\n",
    "#    [default]\n",
    "#    aws_access_key_id = YOUR_ACCESS_KEY\n",
    "#    aws_secret_access_key = YOUR_SECRET_KEY\n",
    "# Option 3. Environment variables: Set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY\n",
    "\n",
    "# Initialize AWS clients using default credential chain\n",
    "sagemaker = boto3.client('sagemaker', region_name=REGION)\n",
    "sts = boto3.client('sts')\n",
    "\n",
    "# Verify credentials\n",
    "try:\n",
    "    identity = sts.get_caller_identity()\n",
    "    print(f\"Successfully authenticated to AWS Account: {identity['Account']}\")\n",
    "\n",
    "    if identity['Account'] != AWS_ACCOUNT_ID:\n",
    "        print(f\"Warning: Connected to account {identity['Account']}, expected {AWS_ACCOUNT_ID}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to authenticate: {e}\")\n",
    "    print(\"Please run 'aws configure' or set up your credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d6e46c870a996",
   "metadata": {},
   "source": [
    "### Create SageMaker Execution Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97124d6d936a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create SageMaker Execution Role\n",
    "role_name = f\"SageMakerInference-ExecutionRole-{AWS_ACCOUNT_ID}\"\n",
    "\n",
    "trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": \"sagemaker.amazonaws.com\"},\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "iam = boto3.client('iam', region_name=REGION)\n",
    "\n",
    "# Create the role\n",
    "role_response = iam.create_role(\n",
    "    RoleName=role_name,\n",
    "    AssumeRolePolicyDocument=json.dumps(trust_policy),\n",
    "    Description='SageMaker execution role with S3 and SageMaker access'\n",
    ")\n",
    "\n",
    "# Attach required policies\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess'\n",
    ")\n",
    "\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess'\n",
    ")\n",
    "\n",
    "SAGEMAKER_EXECUTION_ROLE_ARN = role_response['Role']['Arn']\n",
    "print(f\"Created SageMaker execution role: {SAGEMAKER_EXECUTION_ROLE_ARN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65527f3805a891d",
   "metadata": {},
   "source": [
    "## 1. Configuration **Static** Parameters + Initialize Sagemaker client\n",
    "\n",
    "Update these variables according to your AWS environment and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585628e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Configuration\n",
    "REGION = \"us-east-1\"\n",
    "\n",
    "# ECR Account mapping by region\n",
    "ECR_ACCOUNT_MAP = {\n",
    "    \"us-east-1\": \"708977205387\",\n",
    "    \"us-west-2\": \"176779409107\",\n",
    "    \"eu-west-2\": \"470633809225\",\n",
    "    \"ap-northeast-1\": \"878185805882\"\n",
    "}\n",
    "\n",
    "# Container Image - Replace with the image URI provided by your AWS contact\n",
    "# Two image tags are available (both point to the same image):\n",
    "IMAGE_LATEST = f\"{ECR_ACCOUNT_MAP[REGION]}.dkr.ecr.{REGION}.amazonaws.com/nova-inference-repo:SM-Inference-latest\"\n",
    "IMAGE_VERSIONED = f\"{ECR_ACCOUNT_MAP[REGION]}.dkr.ecr.{REGION}.amazonaws.com/nova-inference-repo:v1.0.0\"\n",
    "\n",
    "# Use the versioned tag for production deployments (recommended)\n",
    "IMAGE = IMAGE_VERSIONED\n",
    "print(f\"IMAGE = {IMAGE}\")\n",
    "print(f\"Available tags:\")\n",
    "print(f\"  Latest: {IMAGE_LATEST}\")\n",
    "print(f\"  Versioned: {IMAGE_VERSIONED}\")\n",
    "\n",
    "# Model Parameters\n",
    "CONTEXT_LENGTH = \"8000\"        # Maximum total context length\n",
    "MAX_CONCURRENCY = \"16\"         # Maximum concurrent sequences\n",
    "\n",
    "# Optional: Default generation config (uncomment to use)\n",
    "DEFAULT_TEMPERATURE = \"0.0\"\n",
    "DEFAULT_TOP_P = \"1.0\"\n",
    "DEFAULT_TOP_K = \"-1\"\n",
    "DEFAULT_MAX_NEW_TOKENS = \"4096\"\n",
    "DEFAULT_LOGPROBS = \"5\"\n",
    "\n",
    "# Build environment variables conditionally\n",
    "environment = {\n",
    "    'CONTEXT_LENGTH': CONTEXT_LENGTH,\n",
    "    'MAX_CONCURRENCY': MAX_CONCURRENCY,\n",
    "}\n",
    "\n",
    "# Add optional parameters if defined\n",
    "if 'DEFAULT_TEMPERATURE' in globals():\n",
    "    environment['DEFAULT_TEMPERATURE'] = DEFAULT_TEMPERATURE\n",
    "if 'DEFAULT_TOP_P' in globals():\n",
    "    environment['DEFAULT_TOP_P'] = DEFAULT_TOP_P\n",
    "if 'DEFAULT_TOP_K' in globals():\n",
    "    environment['DEFAULT_TOP_K'] = DEFAULT_TOP_K\n",
    "if 'DEFAULT_MAX_NEW_TOKENS' in globals():\n",
    "    environment['DEFAULT_MAX_NEW_TOKENS'] = DEFAULT_MAX_NEW_TOKENS\n",
    "if 'DEFAULT_LOGPROBS' in globals():\n",
    "    environment['DEFAULT_LOGPROBS'] = DEFAULT_LOGPROBS\n",
    "\n",
    "print(\"Environment configuration:\")\n",
    "for key, value in environment.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "sagemaker = boto3.client('sagemaker', region_name=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a2e53e",
   "metadata": {},
   "source": [
    "## 2. Configure **Dynamic** Parameters for Test Cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the prefix string to be reflected in model, endpoint config, and endpoint.\n",
    "JOB_NAME = \"Customer-Job-Name\"\n",
    "\n",
    "# Replace with S3 URI of the training output artifact\n",
    "MODEL_S3_LOCATION = \"S3_URI_OF_YOUR_MODEL_ARTIFACTS\" # must end with /\n",
    "  \n",
    "# Model and instance type config for your endpoint\n",
    "TESTCASE = {\n",
    "    \"model\": \"micro\", \n",
    "    \"instance\": \"ml.g5.12xlarge\"\n",
    "}\n",
    "INSTANCE_TYPE = TESTCASE[\"instance\"]\n",
    "MODEL_NAME = JOB_NAME + \"-\" + TESTCASE[\"model\"] + \"-\" + INSTANCE_TYPE.replace(\".\", \"-\")\n",
    "ENDPOINT_CONFIG_NAME = MODEL_NAME + \"-Config\"\n",
    "ENDPOINT_NAME = MODEL_NAME + \"-Endpoint\"\n",
    "\n",
    "print(f\"Model Name: {MODEL_NAME}\")\n",
    "print(f\"Endpoint Config: {ENDPOINT_CONFIG_NAME}\")\n",
    "print(f\"Endpoint Name: {ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ec2356",
   "metadata": {},
   "source": [
    "## 3. Create SageMaker Model + Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76099d14",
   "metadata": {},
   "source": [
    "### 3.1 Create Model and Endpoint Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_model\n",
    "try:\n",
    "    model_response = sagemaker.create_model(\n",
    "        ModelName=MODEL_NAME,\n",
    "        PrimaryContainer={\n",
    "            'Image': IMAGE,\n",
    "            'ModelDataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3Uri': MODEL_S3_LOCATION,\n",
    "                    'S3DataType': 'S3Prefix',\n",
    "                    'CompressionType': 'None'\n",
    "                }\n",
    "            },\n",
    "            'Environment': environment\n",
    "        },\n",
    "        ExecutionRoleArn=SAGEMAKER_EXECUTION_ROLE_ARN,\n",
    "        EnableNetworkIsolation=True\n",
    "    )\n",
    "    print(\"Model created successfully!\")\n",
    "    print(f\"Model ARN: {model_response['ModelArn']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating model: {e}\")\n",
    "\n",
    "# create_endpoint_config\n",
    "try:\n",
    "    production_variant = {\n",
    "        'VariantName': 'primary',\n",
    "        'ModelName': MODEL_NAME,\n",
    "        'InitialInstanceCount': 1,\n",
    "        'InstanceType': INSTANCE_TYPE,\n",
    "    }\n",
    "    config_response = sagemaker.create_endpoint_config(\n",
    "        EndpointConfigName=ENDPOINT_CONFIG_NAME,\n",
    "        ProductionVariants=[production_variant]\n",
    "    )\n",
    "    print(\"Endpoint configuration created successfully!\")\n",
    "    print(f\"Config ARN: {config_response['EndpointConfigArn']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating endpoint config: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3aa358",
   "metadata": {},
   "source": [
    "### 3.2 Create Endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# create_endpoint\n",
    "try:\n",
    "    endpoint_response = sagemaker.create_endpoint(\n",
    "        EndpointName=ENDPOINT_NAME,\n",
    "        EndpointConfigName=ENDPOINT_CONFIG_NAME\n",
    "    )\n",
    "    print(\"Endpoint creation initiated successfully!\")\n",
    "    print(f\"Endpoint ARN: {endpoint_response['EndpointArn']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating endpoint: {e}\")\n",
    "\n",
    "# Keep polling for endpoint status, may take 15-30 minutes\n",
    "print(\"Waiting for endpoint creation to complete...\")\n",
    "print(\"This typically takes 15-30 minutes...\\n\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        response = sagemaker.describe_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "        status = response['EndpointStatus']\n",
    "        \n",
    "        if status == 'Creating':\n",
    "            print(f\"⏳ Status: {status} - Provisioning infrastructure and loading model...\")\n",
    "        elif status == 'InService':\n",
    "            print(f\"✅ Status: {status}\")\n",
    "            print(\"\\nEndpoint creation completed successfully!\")\n",
    "            print(f\"Endpoint Name: {ENDPOINT_NAME}\")\n",
    "            print(f\"Endpoint ARN: {response['EndpointArn']}\")\n",
    "            break\n",
    "        elif status == 'Failed':\n",
    "            print(f\"❌ Status: {status}\")\n",
    "            print(f\"Failure Reason: {response.get('FailureReason', 'Unknown')}\")\n",
    "            print(\"\\nFull response:\")\n",
    "            print(response)\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Status: {status}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking endpoint status: {e}\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)  # Check every 30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5e84b",
   "metadata": {},
   "source": [
    "## 4. Invoke Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0596c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Add timeout configuration\n",
    "config = botocore.config.Config(\n",
    "    read_timeout=120,\n",
    "    connect_timeout=10,\n",
    "    retries={'max_attempts': 3}\n",
    ")\n",
    "\n",
    "runtime_client = boto3.client('sagemaker-runtime', config=config, region_name=REGION)\n",
    "\n",
    "def invoke_nova_endpoint(request_body):\n",
    "    \"\"\"\n",
    "    Invoke Nova endpoint with automatic streaming detection.\n",
    "    \n",
    "    Args:\n",
    "        request_body (dict): Request payload containing prompt and parameters\n",
    "    \n",
    "    Returns:\n",
    "        dict: Response from the model (for non-streaming requests)\n",
    "        None: For streaming requests (prints output directly)\n",
    "    \"\"\"\n",
    "    body = json.dumps(request_body)\n",
    "    is_streaming = request_body.get(\"stream\", False)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Invoking endpoint ({'streaming' if is_streaming else 'non-streaming'})...\")\n",
    "        \n",
    "        if is_streaming:\n",
    "            response = runtime_client.invoke_endpoint_with_response_stream(\n",
    "                EndpointName=ENDPOINT_NAME,\n",
    "                ContentType='application/json',\n",
    "                Body=body\n",
    "            )\n",
    "            \n",
    "            event_stream = response['Body']\n",
    "            for event in event_stream:\n",
    "                print(\"Event:\", event)\n",
    "                if 'PayloadPart' in event:\n",
    "                    chunk = event['PayloadPart']\n",
    "                    if 'Bytes' in chunk:\n",
    "                        data = chunk['Bytes'].decode()\n",
    "                        print(\"Chunk: \", data)\n",
    "        else:\n",
    "            response = runtime_client.invoke_endpoint(\n",
    "                EndpointName=ENDPOINT_NAME,\n",
    "                ContentType='application/json',\n",
    "                Accept='application/json',\n",
    "                Body=body\n",
    "            )\n",
    "            \n",
    "            response_body = response['Body'].read().decode('utf-8')\n",
    "            result = json.loads(response_body)\n",
    "            print(\"Response: \", result)\n",
    "            return result\n",
    "    \n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Error: {e.response['Error']['Code']} - {e.response['Error']['Message']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583909a",
   "metadata": {},
   "source": [
    "### Test both Streaming & Non-Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc94f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Non-streaming chat\n",
    "chat_request = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hello! How are you?\"}\n",
    "    ],\n",
    "    \"max_tokens\": 100,\n",
    "    \"max_completion_tokens\": 100,\n",
    "    \"stream\": False,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"top_k\": 50,\n",
    "    \"logprobs\": True,\n",
    "    \"top_logprobs\": 3,\n",
    "    # \"reasoning_effort\": \"low\",  # Options: \"low\", \"high\"\n",
    "    \"allowed_token_ids\": None,  # List of allowed token IDs\n",
    "    \"truncate_prompt_tokens\": None,  # Truncate prompt to this many tokens\n",
    "    \"stream_options\": None\n",
    "}\n",
    "\n",
    "response = invoke_nova_endpoint(chat_request)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test 2: Non-streaming completion\n",
    "completion_request = {\n",
    "    \"prompt\": \"The capital of France is\",\n",
    "    \"max_tokens\": 50,\n",
    "    \"stream\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"top_k\": -1,  # -1 means no limit\n",
    "    \"logprobs\": 3,  # Number of log probabilities to return\n",
    "    \"allowed_token_ids\": None,  # List of allowed token IDs\n",
    "    \"truncate_prompt_tokens\": None,  # Truncate prompt to this many tokens\n",
    "    \"stream_options\": None\n",
    "}\n",
    "\n",
    "response = invoke_nova_endpoint(completion_request)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test 3: Streaming chat\n",
    "streaming_chat_request = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a short story about a robot\"}\n",
    "    ],\n",
    "    \"max_tokens\": 200,\n",
    "    \"stream\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"logprobs\": True,\n",
    "    \"top_logprobs\": 2,\n",
    "    # \"reasoning_effort\": \"high\",  # Options: \"low\", \"high\"\n",
    "    \"stream_options\": {\"include_usage\": True}\n",
    "}\n",
    "\n",
    "invoke_nova_endpoint(streaming_chat_request)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test 4: Streaming completion\n",
    "streaming_completion_request = {\n",
    "    \"prompt\": \"The capital of France is\",\n",
    "    \"max_tokens\": 50,\n",
    "    \"stream\": True,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"top_k\": -1,  # -1 means no limit\n",
    "    \"logprobs\": 3,  # Number of log probabilities to return\n",
    "    \"allowed_token_ids\": None,  # List of allowed token IDs\n",
    "    \"truncate_prompt_tokens\": None,  # Truncate prompt to this many tokens\n",
    "    \"stream_options\": {\"include_usage\": True}\n",
    "}\n",
    "\n",
    "invoke_nova_endpoint(streaming_completion_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b02769",
   "metadata": {},
   "source": [
    "## List ALL existing resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab59d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sagemaker.list_models())\n",
    "print(sagemaker.list_endpoint_configs())\n",
    "print(sagemaker.list_endpoints())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
