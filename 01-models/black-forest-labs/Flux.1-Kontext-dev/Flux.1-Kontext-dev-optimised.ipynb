{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151297c4",
   "metadata": {},
   "source": [
    "# Deploying a pruna optimised version of Flux Kontext Dev on sagemaker\n",
    "\n",
    "This sample showcases how to optimise and deploy Flux Kontext dev from Black Forest Lab (available on <a href=\"https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev\">HuggingFace</a>) using <a href=\"https://aws.amazon.com/sagemaker/\">Amazon Sagemaker</a> and <a href=\"https://github.com/PrunaAI\">Pruna open source library</a>.\n",
    "\n",
    "NOTE: Usage of Flux Kontext Dev is subject to licensing available <a href=\"https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev\">here</a>.\n",
    "\n",
    "Optimisation implemented in this sample shows a 3.5x speed-up (63sec > 21sec) with similar output quality.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6b85e",
   "metadata": {},
   "source": [
    "## Requirements and instructions\n",
    "\n",
    "You can run this notebook locally (laptop for eg.) as it leverages Amazon Sagemaker infrastructure for model preparation and deployment. You could also run it from an Amazon Sagemaker AI studio (ex. Code Editor).\n",
    "\n",
    "Python version: 3.10.18.\n",
    "Torch version : At time of writing, PyTorch Deep Learning Container is not available for PyTorch 2.7.0 requiring upgrade from 2.6 in training job and endpoint deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d17ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch==2.7.0 --extra-index-url https://download.pytorch.org/whl/cu128\n",
    "%pip install torchaudio==2.7.0\n",
    "%pip install torchvision==0.22.0\n",
    "%pip install diffusers==0.35.1\n",
    "%pip install transformers==4.51.0\n",
    "%pip install huggingface_hub>=0.34.4\n",
    "%pip install boto3\n",
    "%pip install sagemaker\n",
    "%pip install sagemaker-huggingface-inference-toolkit>=2.6.0\n",
    "%pip install peft>=0.17.0\n",
    "%pip install accelerate\n",
    "%pip install sentencepiece\n",
    "%pip install pillow\n",
    "%pip install protobuf\n",
    "%pip install matplotlib\n",
    "%pip install pruna\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d46eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from diffusers import FluxKontextPipeline\n",
    "from diffusers.utils import load_image\n",
    "from huggingface_hub import login\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.remote_function import remote\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.s3 import S3Downloader\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "from pruna import SmashConfig, smash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"us-east-1\"\n",
    "HF_TOKEN = \"your_token_here\"\n",
    "model_subfolder = \"flux-smashed\"\n",
    "\n",
    "sess = sagemaker.Session(boto_session=boto3.session.Session(region_name=region))\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    # If you current identity is not a role, you may hardcode the role arn here\n",
    "    role = \"arn_of_your_sagemaker_execution_role\"\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e363a",
   "metadata": {},
   "source": [
    "## Packaging local code to S3\n",
    "\n",
    "Inference code and requirements are available in this repository. This code packages the 2 files to S3 which will be used during model preparation in the training job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(tar_dir=None, output_file=\"code.tar.gz\"):\n",
    "    parent_dir=os.getcwd()\n",
    "    os.chdir(parent_dir)\n",
    "    with tarfile.open(os.path.join(parent_dir, output_file), \"w:gz\") as tar:\n",
    "        for item in os.listdir('.'):\n",
    "          tar.add(item, arcname=item)    \n",
    "    os.chdir(parent_dir)\n",
    "\n",
    "compress(str(Path(\"code\")))\n",
    "\n",
    "s3_model_uri=S3Uploader.upload(local_path=\"code.tar.gz\", desired_s3_uri=f\"s3://{sess.default_bucket()}/{model_subfolder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321ca8c",
   "metadata": {},
   "source": [
    "## Smashing model in sagemaker training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = dict(\n",
    "    sagemaker_session=sess,\n",
    "    role=role,\n",
    "    instance_type=\"ml.g6e.xlarge\",\n",
    "    volume_size=250,\n",
    "    dependencies='./code/requirements.txt'\n",
    ")\n",
    "\n",
    "@remote(**settings)\n",
    "def smash_model_hf(model_id):\n",
    "\n",
    "    # Hugging face lib will store model artifacts here, needed due to size of model\n",
    "    import os\n",
    "    os.environ['HF_HOME'] = '/tmp/cache/'\n",
    "\n",
    "    # getting a new sagemaker session on the training instance\n",
    "    remote_session = sagemaker.Session(boto_session=boto3.session.Session(region_name=region))\n",
    "\n",
    "    # S3 download of code + uncompress\n",
    "    # This is quicker than using the source_dir which repackages the whole model\n",
    "    S3Downloader.download(s3_uri=f\"s3://{remote_session.default_bucket()}/{model_subfolder}/code.tar.gz\",local_path=\"/tmp\")\n",
    "    tar = tarfile.open(\"/tmp/code.tar.gz\", \"r:gz\")\n",
    "    tar.extractall(path=\"/tmp/code\")\n",
    "    tar.close()\n",
    "\n",
    "    # Moving the files to the sagemaker required output folder\n",
    "    shutil.copytree(\"/tmp/code\", \"/opt/ml/model/code\", dirs_exist_ok = True)\n",
    "    login(token = HF_TOKEN)\n",
    "    \n",
    "    pipe = FluxKontextPipeline.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n",
    "    pipe.to(\"cuda\")\n",
    "\n",
    "    # Pruna configuration\n",
    "    smash_config = SmashConfig(device='cuda')\n",
    "    smash_config[\"cacher\"] = \"fora\"\n",
    "    smash_config[\"fora_interval\"] = 2  # 3, 4\n",
    "    smash_config[\"compiler\"] = \"torch_compile\"\n",
    "    smash_config[\"torch_compile_mode\"] = \"max-autotune-no-cudagraphs\"\n",
    "    smash_config[\"quantizer\"] = \"torchao\"\n",
    "    smash_config[\"torchao_quant_type\"] = \"int8dq\"\n",
    "    smash_config[\"torchao_excluded_modules\"] = \"norm+embedding\"\n",
    "    smash_config[\"torch_compile_make_portable\"] = True\n",
    "\n",
    "    smashed_pipe = smash(model=pipe, smash_config=smash_config)\n",
    "\n",
    "    # running inference post-optimisation to construct the compilation graph\n",
    "    prompt = \"Add a fun hat to the dog on the right and a top hat to the dog on the left\"\n",
    "    input_image = load_image(\"https://images.pexels.com/photos/1108099/pexels-photo-1108099.jpeg\")\n",
    "    pipe(\n",
    "        image=input_image,\n",
    "        prompt=prompt,\n",
    "        guidance_scale=2.5,\n",
    "        num_inference_steps=50\n",
    "    )[\"images\"]\n",
    "\n",
    "    smashed_pipe.save_pretrained(\"/opt/ml/model/flux_smashed\")\n",
    "\n",
    "    return os.environ.get('TRAINING_JOB_ARN')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0aef2",
   "metadata": {},
   "source": [
    "# Starting the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can take 30-90min\n",
    "training_job_arn = smash_model_hf(\"black-forest-labs/FLUX.1-Kontext-dev\")\n",
    "training_job_arn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the name from the job arn\n",
    "training_job_name = training_job_arn.split('/')[-1]\n",
    "\n",
    "# Get the model artifact S3 URI\n",
    "job_description = sess.describe_training_job(training_job_name)\n",
    "model_data = job_description['ModelArtifacts']['S3ModelArtifacts']\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f8b00",
   "metadata": {},
   "source": [
    "## Deploy model to sagemaker real time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env={\n",
    "   'SAGEMAKER_MODEL_SERVER_TIMEOUT':'1200', \n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=env,\n",
    "   model_data=model_data,      \n",
    "   role=role,                    \n",
    "   transformers_version=\"4.49.0\",  \n",
    "   pytorch_version=\"2.6.0\",       # pytorch version used, which will be updated at runtime\n",
    "   py_version='py312'            # python version used for deployment\n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g6e.xlarge\",\n",
    "    model_data_download_timeout=1200, \n",
    "    container_startup_health_check_timeout=1200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51abd03",
   "metadata": {},
   "source": [
    "# Testing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for base64 and images\n",
    "\n",
    "def decode_base64_image(image_string):\n",
    "  base64_image = base64.b64decode(image_string)\n",
    "  buffer = BytesIO(base64_image)\n",
    "  return Image.open(buffer)\n",
    "\n",
    "def display_images(images=None,columns=3, width=100, height=100):\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "\n",
    "def encode_image(image):\n",
    "  buffered = BytesIO()\n",
    "  image.save(buffered, format=\"JPEG\")\n",
    "  img_str = base64.b64encode(buffered.getbuffer()).decode()\n",
    "  return img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free to use image according to license in pexels - https://www.pexels.com/license/\n",
    "input_image = load_image(\"https://images.pexels.com/photos/1108099/pexels-photo-1108099.jpeg\")\n",
    "str_imge = encode_image(input_image)\n",
    "\n",
    "# run prediction\n",
    "prompt = \"Add a fun hat to the dog on the right and a top hat to the dog on the left\"\n",
    "\n",
    "response = predictor.predict({\n",
    "  \"input_image\": str_imge,\n",
    "  \"inputs\": prompt,\n",
    "  \"guidance_scale\": 2.5,\n",
    "  \"num_inference_steps\": 50\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode images\n",
    "decoded_images = [decode_base64_image(image) for image in response[\"generated_images\"]]\n",
    "\n",
    "# visualize generation\n",
    "display_images(decoded_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cbd9e",
   "metadata": {},
   "source": [
    "# Cleanup resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
