{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993dcf59-dd85-4a31-a8cc-02c5d4be5dfe",
   "metadata": {},
   "source": [
    "# Deploy Wan2.1-T2V-1.3B-Diffusers on SageMaker using HuggingFace Inference Containers\n",
    "\n",
    "This notebook demonstrates how to deploy [Wan-AI/Wan2.1-T2V-1.3B-Diffusers](https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B-Diffusers) text to video model on Amazon SageMaker AI endpoint.\n",
    "\n",
    "The notebook was tested in Amazon SageMaker AI Studio environment and it's recommended to run it in the Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed95e23d-4578-43a1-ae0f-c0bffed7d5f6",
   "metadata": {},
   "source": [
    "## 1. Environment preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01a4b2-b0d3-420c-8335-4efd984bb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker==2.254.1 --upgrade --quiet --no-warn-conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183bf15-3f3f-4d70-91da-fe269ff421b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")  # client to intreract with SageMaker\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")  # client to intreract with SageMaker Endpoints\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")\n",
    "print(f\"sagemaker session region: {region}\")\n",
    "print(f\"boto3 version: {boto3.__version__}\")\n",
    "print(f\"sagemaker version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82a461-d560-4db1-bb91-306cb86bfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Wan-AI/Wan2.1-T2V-1.3B-Diffusers\"\n",
    "s3_key = f\"model/{model_id}\"\n",
    "s3_code_key = f\"{s3_key}/code\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965df386-26dc-4cc8-a90c-696ca74a70f7",
   "metadata": {},
   "source": [
    "## 2. Model and inference logic preparation\n",
    "\n",
    "Although it's possible to deploy a model on SageMaker AI endpoint directly from the HuggingFace Hub in production scenario the model is usually deployed from Amazon S3 bucket.\n",
    "To simulate the production deployment, we are going to download the model from the HF hub and upload to the S3 bucket.\n",
    "\n",
    "Also, we are going to prepare `requirements.txt` with a list of additional Python libraries and `inference.py` which contains custom model loading and inference code.\n",
    "\n",
    "***P.S. you can skip this step if model and required files were uploaded to the S3 previously***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153e950-acb9-4372-9187-6812d6dbafd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_path = Path(\"./data\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "\n",
    "snapshot_download(repo_id=model_id, local_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a984eb-046f-47d9-a2a4-7d58e403cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate local files recursively\n",
    "for root, dirs, files in os.walk(local_model_path):\n",
    "    for filename in files:\n",
    "        local_path = os.path.join(root, filename)\n",
    "\n",
    "        relative_path = os.path.relpath(local_path, local_model_path)\n",
    "        s3_path = os.path.join(s3_key, relative_path)\n",
    "\n",
    "        print(\"Uploading %s...\" % s3_path)\n",
    "        s3.upload_file(local_path, bucket, s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6185c57-c8f5-4053-a169-43099b79b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = \"\"\"torchvision==0.21.0\n",
    "opencv-python==4.11.0.86\n",
    "diffusers==0.35.2\n",
    "transformers==4.49.0\n",
    "tokenizers==0.21.1\n",
    "accelerate==1.4.0\n",
    "peft==0.17.1\n",
    "ftfy==6.3.1\n",
    "ffmpeg==1.4\n",
    "imageio==2.37.2\n",
    "imageio-ffmpeg==0.6.0\n",
    "\"\"\"\n",
    "file_name = \"requirements.txt\"\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "key = f\"{s3_code_key}/{file_name}\"\n",
    "s3.upload_file(file_name, bucket, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd1d91-a33b-448e-ad80-fcee0e356d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = \"\"\"import os\n",
    "import time\n",
    "import boto3\n",
    "import torch\n",
    "from botocore.exceptions import ClientError\n",
    "from diffusers import AutoencoderKLWan, WanPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "\n",
    "    # Upload the file\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        s3.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    vae = AutoencoderKLWan.from_pretrained(model_dir, subfolder=\"vae\", torch_dtype=torch.float32)\n",
    "    pipe = WanPipeline.from_pretrained(model_dir, vae=vae, torch_dtype=torch.bfloat16)\n",
    "    pipe.to(\"cuda\")\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def predict_fn(data, pipe):\n",
    "    print(\"inference started\")\n",
    "\n",
    "    bucket = data.pop(\"bucket\")\n",
    "    file_name = data.pop(\"file_name\", \"model_output.mp4\")\n",
    "    prompt = data.pop(\"prompt\", \"A curious raccoon\")\n",
    "    negative_prompt = data.pop(\"negative_prompt\", \"Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards\")\n",
    "    height = int(data.pop(\"height\", 480))\n",
    "    width = int(data.pop(\"width\", 832))\n",
    "    num_frames = int(data.pop(\"num_frames\", 17))\n",
    "    guidance_scale = float(data.pop(\"guidance_scale\", 5.0))\n",
    "    fps = int(data.pop(\"fps\", 15))\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    output = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_frames=num_frames,\n",
    "        guidance_scale=guidance_scale\n",
    "    ).frames[0]\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Execution time - in PREDICT : {elapsed_time:.6f} seconds\")\n",
    "\n",
    "    file_path = f\"/tmp/{os.path.basename(file_name)}\"\n",
    "    export_to_video(output, file_path, fps)\n",
    "\n",
    "    upload_file(file_path, bucket, file_name)\n",
    "\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return {\"generated_video\": f\"s3://{bucket}/{file_name}\"}\n",
    "\"\"\"\n",
    "file_name = \"inference.py\"\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write(inference)\n",
    "\n",
    "key = f\"{s3_code_key}/{file_name}\"\n",
    "s3.upload_file(file_name, bucket, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d390702-1b06-433d-95a4-5e92be2e5b69",
   "metadata": {},
   "source": [
    "## 3. Model deployment\n",
    "\n",
    "Model deployment on Amazon SageMaker AI consist of 3 steps:\n",
    "- [create model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_model.html) object (serving container and location of model artifacts)\n",
    "- [create endpoint configuration](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_endpoint_config.html) (endpoint type: real-time/async, instance type and count)\n",
    "- [create endpoint](https://boto3.amazonaws.com/v1/documentation/api/1.40.48/reference/services/sagemaker-runtime/client/invoke_endpoint_async.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59c633-4d9e-4dfd-82c3-b639cba583ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/huggingface-pytorch-inference:2.6.0-transformers4.49.0-gpu-py312-cu124-ubuntu22.04\"\n",
    "\n",
    "instance = {\"type\": \"ml.g6e.2xlarge\", \"num_gpu\": 1}\n",
    "model_name = f\"model-{time.strftime('%y%m%d-%H%M%S')}\"\n",
    "endpoint_name = model_name\n",
    "endpoint_config_name = model_name\n",
    "timeout = 600\n",
    "variant_name = \"main\"\n",
    "\n",
    "model_data_source = {\n",
    "    'S3DataSource': {\n",
    "        'S3Uri': f\"s3://{bucket}/{s3_key}/\",\n",
    "        'S3DataType': 'S3Prefix',\n",
    "        'CompressionType': 'None',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cde442-9540-4b00-8513-6afd49de5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image,\n",
    "        \"ModelDataSource\": model_data_source\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9b3a3-6729-472e-b385-d195503fcd57",
   "metadata": {},
   "source": [
    "\n",
    "**We are going to use ASYNC endpoint because video generation can exceed real-time endpoint timeout (12 mins).**\n",
    "\n",
    "The `NotificationConfig` is optional. Please remove this entry if you don't want to be notified when inference request has been processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c37f0-6a2e-4a0c-8630-70429dacaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_topic = \"<YOUR_SNS_TOPIC>\"\n",
    "\n",
    "async_config = {\n",
    "    'ClientConfig': {\n",
    "        'MaxConcurrentInvocationsPerInstance': 5\n",
    "    },\n",
    "    'OutputConfig': {\n",
    "        'S3OutputPath': f\"s3://{bucket}/async/out\",\n",
    "        'NotificationConfig': {\n",
    "            'SuccessTopic': sns_topic,\n",
    "            'ErrorTopic': sns_topic,\n",
    "            'IncludeInferenceResponseIn': ['SUCCESS_NOTIFICATION_TOPIC']\n",
    "        },\n",
    "        'S3FailurePath': f\"s3://{bucket}/async/err\"\n",
    "    }\n",
    "}\n",
    "\n",
    "config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": variant_name,\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance[\"type\"],\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": timeout,\n",
    "        },\n",
    "    ],\n",
    "    AsyncInferenceConfig=async_config,\n",
    ")\n",
    "\n",
    "endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "_ = sess.wait_for_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd9396-da68-4367-8d84-7be06228100d",
   "metadata": {},
   "source": [
    "## 4. Inference examples\n",
    "\n",
    "**Please note that the generated video file will be placed in `{bucket}/{key}` specified in the invocation request**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852ab5c-9364-4141-8af0-13d208b382e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = f\"\"\"\n",
    "{{\n",
    "    \"bucket\": \"{bucket}\",\n",
    "    \"file_name\": \"test_video1.mp4\",\n",
    "    \"prompt\": \"A cat walks on the grass, realistic\",\n",
    "    \"num_frames\": 161\n",
    "}}\n",
    "\"\"\"\n",
    "file_name = \"request1.txt\"\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write(payload)\n",
    "\n",
    "key = f\"async/in/{file_name}\"\n",
    "s3.upload_file(file_name, bucket, key)\n",
    "\n",
    "res = smr_client.invoke_endpoint_async(\n",
    "    EndpointName = endpoint_name,\n",
    "    ContentType = \"application/json\",\n",
    "    InputLocation = f\"s3://{bucket}/{key}\",\n",
    ")\n",
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d569e-6392-4641-aec7-7c017e0718e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = f\"\"\"\n",
    "{{\n",
    "    \"bucket\": \"{bucket}\",\n",
    "    \"file_name\": \"test_video2.mp4\",\n",
    "    \"prompt\": \"A curious racoon standing and looking directly at the camera near a garbage bin\",\n",
    "    \"num_frames\": 161\n",
    "}}\n",
    "\"\"\"\n",
    "file_name = \"request2.txt\"\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write(payload)\n",
    "\n",
    "key = f\"async/in/{file_name}\"\n",
    "s3.upload_file(file_name, bucket, key)\n",
    "\n",
    "res = smr_client.invoke_endpoint_async(\n",
    "    EndpointName = endpoint_name,\n",
    "    ContentType = \"application/json\",\n",
    "    InputLocation = f\"s3://{bucket}/{key}\",\n",
    ")\n",
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a04e2-e88f-48a8-8668-27564c86f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = f\"\"\"\n",
    "{{\n",
    "    \"bucket\": \"{bucket}\",\n",
    "    \"file_name\": \"test_video3.mp4\",\n",
    "    \"prompt\": \"A skilled archery champion, a lean and muscular woman in her late 20s, with sharp, focused hazel eyes, high cheekbones, and sun-kissed olive skin. Her dark brown hair is tied back in a tight braid, a few loose strands framing her face. She wears a fitted leather tunic in deep forest green, reinforced with subtle stitching, over a long-sleeved linen undershirt. Her hands move with precision as she fletches arrows, carefully binding hawk feathers to the shafts with sinew. Her expression is calm but intense, lips slightly pursed in concentration. The workshop around her is cluttered with wooden shafts, fletching tools, and a quiver of finished arrows. Warm torchlight casts flickering shadows on the rough-hewn wooden walls. She is wearing a blue jade bead necklace.\",\n",
    "    \"num_frames\": 161\n",
    "}}\n",
    "\"\"\"\n",
    "file_name = \"request3.txt\"\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write(payload)\n",
    "\n",
    "key = f\"async/in/{file_name}\"\n",
    "s3.upload_file(file_name, bucket, key)\n",
    "\n",
    "res = smr_client.invoke_endpoint_async(\n",
    "    EndpointName = endpoint_name,\n",
    "    ContentType = \"application/json\",\n",
    "    InputLocation = f\"s3://{bucket}/{key}\",\n",
    ")\n",
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f52bc-dd0b-43a0-ad71-829b3d80ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = f\"\"\"\n",
    "{{\n",
    "    \"bucket\": \"{bucket}\",\n",
    "    \"file_name\": \"test_video4.mp4\",\n",
    "    \"prompt\": \"A traditional Christmas dinner table with candles and presents\",\n",
    "    \"num_frames\": 161\n",
    "}}\n",
    "\"\"\"\n",
    "file_name = \"request4.txt\"\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write(payload)\n",
    "\n",
    "key = f\"async/in/{file_name}\"\n",
    "s3.upload_file(file_name, bucket, key)\n",
    "\n",
    "res = smr_client.invoke_endpoint_async(\n",
    "    EndpointName = endpoint_name,\n",
    "    ContentType = \"application/json\",\n",
    "    InputLocation = f\"s3://{bucket}/{key}\",\n",
    ")\n",
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198cf8d-2c54-4db1-99a6-8c3db09f14fb",
   "metadata": {},
   "source": [
    "## 5. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb12ccb4-f9f1-431f-a9ff-9af038624f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_config_name)\n",
    "sess.delete_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b74a1d-bdde-4e4b-a1d3-ced1deb2feb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
